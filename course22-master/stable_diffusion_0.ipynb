{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cdc0314-f917-4ecc-9557-9d9e5c4b9d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f92a819-fd6d-4712-bc9d-32631c7613f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josef\\anaconda3\\envs\\huggingfagface\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from IPython import display as IPdisplay\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import (\n",
    "    DDIMScheduler,\n",
    "    PNDMScheduler,\n",
    "    LMSDiscreteScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    ")\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d821b62f-2ab9-41a5-ad9e-b396a2910209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipywidgets) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\josef\\anaconda3\\envs\\huggingfagface\\lib\\site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed12792c-3dae-46f8-9f83-1bfd9342ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21dc1b60-319e-4ae1-bead-08d0af6241ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a1851-7b62-463c-a6de-4771113611fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  14%|█▍        | 1/7 [00:00<00:02,  2.49it/s]"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "scheduler = LMSDiscreteScheduler(\n",
    "    beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000\n",
    ")\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    scheduler=scheduler,\n",
    "    torch_dtype=torch.float32,\n",
    ").to(device)\n",
    "\n",
    "# Disable image generation progress bar, we'll display our own\n",
    "pipe.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a12e6a-d456-4c0e-b0d7-ede8f2ccd57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offloading the weights to the CPU and only loading them on the GPU can reduce memory consumption to less than 3GB.\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# Tighter ordering of memory tensors.\n",
    "pipe.unet.to(memory_format=torch.channels_last)\n",
    "\n",
    "# Decoding large batches of images with limited VRAM or batches with 32 images or more by decoding the batches of latents one image at a time.\n",
    "pipe.enable_vae_slicing()\n",
    "\n",
    "# Splitting the image into overlapping tiles, decoding the tiles, and then blending the outputs together to compose the final image.\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "# Using Flash Attention; If you have PyTorch >= 2.0 installed, you should not expect a speed-up for inference when enabling xformers.\n",
    "pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67be4e7-78f3-4c76-aee8-61a8e3eb40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, save_path):\n",
    "    try:\n",
    "        # Convert each image in the 'images' list from an array to an Image object.\n",
    "        images = [Image.fromarray(np.array(image[0], dtype=np.uint8)) for image in images]\n",
    "\n",
    "        # Generate a file name based on the current time, replacing colons with hyphens\n",
    "        # to ensure the filename is valid for file systems that don't allow colons.\n",
    "        filename = time.strftime(\"%H:%M:%S\", time.localtime()).replace(\":\", \"-\")\n",
    "        # Save the first image in the list as a GIF file at the 'save_path' location.\n",
    "        # The rest of the images in the list are added as subsequent frames to the GIF.\n",
    "        # The GIF will play each frame for 100 milliseconds and will loop indefinitely.\n",
    "        images[0].save(\n",
    "            f\"{save_path}/{filename}.gif\",\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            duration=100,\n",
    "            loop=0,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # If there is an error during the process, print the exception message.\n",
    "        print(e)\n",
    "\n",
    "    # Return the saved GIF as an IPython display object so it can be displayed in a notebook.\n",
    "    return IPdisplay.Image(f\"{save_path}/{filename}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644ca96-0ac6-4f34-8fef-89425e991b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The seed is set to \"None\", because we want different results each time we run the generation.\n",
    "seed = None\n",
    "\n",
    "if seed is not None:\n",
    "    generator = torch.manual_seed(seed)\n",
    "else:\n",
    "    generator = None\n",
    "\n",
    "# The guidance scale is set to its normal range (7 - 10).\n",
    "guidance_scale = 8\n",
    "\n",
    "# The number of inference steps was chosen empirically to generate an acceptable picture within an acceptable time.\n",
    "num_inference_steps = 15\n",
    "\n",
    "# The higher you set this value, the smoother the interpolations will be. However, the generation time will increase. This value was chosen empirically.\n",
    "num_interpolation_steps = 30\n",
    "\n",
    "# I would not recommend less than 512 on either dimension. This is because this model was trained on 512x512 image resolution.\n",
    "height = 512\n",
    "width = 512\n",
    "\n",
    "# The path where the generated GIFs will be saved\n",
    "save_path = \"/output\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321c95e-d8e0-43c5-871f-8d01c68f0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Epic shot of Sweden, ultra detailed lake with an ren dear, nostalgic vintage, ultra cozy and inviting, wonderful light atmosphere, fairy, little photorealistic, digital painting, sharp focus, ultra cozy and inviting, wish to be there. very detailed, arty, should rank high on youtube for a dream trip.\"\n",
    "# A negative prompt that can be used to steer the generation away from certain features; here, it is empty.\n",
    "negative_prompt = \"poorly drawn,cartoon, 2d, disfigured, bad art, deformed, poorly drawn, extra limbs, close up, b&w, weird colors, blurry\"\n",
    "\n",
    "# The step size for the interpolation in the latent space.\n",
    "step_size = 0.001\n",
    "\n",
    "# Tokenizing and encoding the prompt into embeddings.\n",
    "prompt_tokens = pipe.tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=pipe.tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "prompt_embeds = pipe.text_encoder(prompt_tokens.input_ids.to(device))[0]\n",
    "\n",
    "\n",
    "# Tokenizing and encoding the negative prompt into embeddings.\n",
    "if negative_prompt is None:\n",
    "    negative_prompt = [\"\"]\n",
    "\n",
    "negative_prompt_tokens = pipe.tokenizer(\n",
    "    negative_prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=pipe.tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "negative_prompt_embeds = pipe.text_encoder(negative_prompt_tokens.input_ids.to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950b7d1-c7db-4707-898f-7513116049b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " Generating initial latent vectors from a random normal distribution, with the option to use a generator for reproducibility.\n",
    "latents = torch.randn(\n",
    "    (1, pipe.unet.config.in_channels, height // 8, width // 8),\n",
    "    generator=generator,\n",
    ")\n",
    "\n",
    "walked_embeddings = []\n",
    "\n",
    "# Interpolating between embeddings for the given number of interpolation steps.\n",
    "for i in range(num_interpolation_steps):\n",
    "    walked_embeddings.append([prompt_embeds + step_size * i, negative_prompt_embeds + step_size * i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7114796-8e2f-4b41-a707-7b543c851905",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for latent in tqdm(walked_embeddings):\n",
    "    images.append(\n",
    "        pipe(\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_images_per_prompt=1,\n",
    "            prompt_embeds=latent[0],\n",
    "            negative_prompt_embeds=latent[1],\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            latents=latents,\n",
    "        ).images\n",
    "    )\n",
    "\n",
    "# Display of saved generated images.\n",
    "display_images(images, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
